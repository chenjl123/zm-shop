# 数据库访问配置
spring.datasource.type=com.alibaba.druid.pool.DruidDataSource
spring.datasource.driverClassName = com.mysql.jdbc.Driver
spring.datasource.url = jdbc:mysql://127.0.0.1:3306/order?allowMultiQueries=true&amp;useUnicode=true&amp;characterEncoding=utf-8
spring.datasource.username = root
spring.datasource.password = root
# 下面为连接池的补充设置，应用到上面所有数据源中
# 初始化大小，最小，最大
spring.datasource.initialSize=5
spring.datasource.minIdle=5
spring.datasource.maxActive=20
# 配置获取连接等待超时的时间
spring.datasource.maxWait=60000
# 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒
spring.datasource.timeBetweenEvictionRunsMillis=60000
# 配置一个连接在池中最小生存的时间，单位是毫秒
spring.datasource.minEvictableIdleTimeMillis=300000
# Oracle请使用select 1 from dual
spring.datasource.validationQuery=SELECT 'X' FROM DUAL
spring.datasource.testWhileIdle=true
spring.datasource.testOnBorrow=false
spring.datasource.testOnReturn=false
# 打开PSCache，并且指定每个连接上PSCache的大小
spring.datasource.poolPreparedStatements=true
spring.datasource.maxPoolPreparedStatementPerConnectionSize=20
# 配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙
spring.datasource.filters=stat,wall,log4j
# 通过connectProperties属性来打开mergeSql功能；慢SQL记录
spring.datasource.connectionProperties=druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000
# 合并多个DruidDataSource的监控数据
spring.datasource.useGlobalDataSourceStat=true

###########################kafka配置

#协议转换后存储kafka
#(kafka生产集群ip+port端口)
kafka.producer.servers= 192.168.55.132:9092   
#(生产的topic)
kafka.producer.topic=test008
#设置大于0的值将使客户端重新发送任何数据，一旦这些数据发送失败
kafka.producer.retries=0
#0: producer不会等待broker发送ack。生产者只要把消息发送给broker之后，就认为发送成功了，这是第1种情况；
#1: 当leader接收到消息之后发送ack。生产者把消息发送到broker之后，并且消息被写入到本地文件，才认为发送成功，这是第二种情况；
#-1(all): 当所有的follower都同步消息成功后发送ack。不仅是主的分区将消息保存成功了，  默认-1
kafka.producer.acks=0
#这项配置控制默认的批量处理消息字节数
kafka.producer.batch.size=4096
kafka.producer.linger=1
#producer可以用来缓存数据的内存大小
kafka.producer.buffer.memory=40960
